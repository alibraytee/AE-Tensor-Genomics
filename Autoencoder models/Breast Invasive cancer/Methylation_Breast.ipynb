{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 22)\n",
      "(185, 22)\n",
      "(492, 22)\n",
      "(124, 22)\n",
      "data loading time:  943.7239739894867\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "methy_breast = pd.read_csv('data_methylation_B.csv')\n",
    "methy_breast_update = methy_breast.rename(columns={\"Unnamed: 0\": \"attrib_name\"})\n",
    "\n",
    "\n",
    "train_clinical73_B = pd.read_csv('train_clinical_B73.csv')\n",
    "#train_clinical73_B = train_clinical73_B.rename(columns={\"Unnamed: 0.1\": \"attrib_name\"})\n",
    "\n",
    "test_clinical73_B = pd.read_csv('test_clinical_B73.csv')\n",
    "#test_clinical73_B = test_clinical73_B.rename(columns={\"Unnamed: 0.1\": \"attrib_name\"})\n",
    "print(train_clinical73_B.shape)\n",
    "print(test_clinical73_B.shape)\n",
    "\n",
    "train_clinical82_B = pd.read_csv('train_clinical_B82.csv')\n",
    "#train_clinical82_B = train_clinical82_B.rename(columns={\"Unnamed: 0.1\": \"attrib_name\"})\n",
    "\n",
    "test_clinical82_B = pd.read_csv('test_clinical_B82.csv')\n",
    "#test_clinical82_B = test_clinical82_B.rename(columns={\"Unnamed: 0.1\": \"attrib_name\"})\n",
    "print(train_clinical82_B.shape)\n",
    "print(test_clinical82_B.shape)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "exec_time = end - start\n",
    "print(\"data loading time: \", exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receive the index so that we can match each techs\n",
    "train_idx_82B = train_clinical82_B[['attrib_name']]\n",
    "test_idx_82B = test_clinical82_B[['attrib_name']]\n",
    "\n",
    "train_idx_73B = train_clinical73_B[['attrib_name']]\n",
    "test_idx_73B = test_clinical73_B[['attrib_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attrib_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA.OK.A5Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA.OL.A5D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA.BH.A8G0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA.D8.A1JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA.E9.A24A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>TCGA.AC.A2QI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>TCGA.D8.A1XC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>TCGA.E2.A1IJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>TCGA.E2.A14U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>TCGA.EW.A6SC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attrib_name\n",
       "0    TCGA.OK.A5Q2\n",
       "1    TCGA.OL.A5D7\n",
       "2    TCGA.BH.A8G0\n",
       "3    TCGA.D8.A1JP\n",
       "4    TCGA.E9.A24A\n",
       "..            ...\n",
       "487  TCGA.AC.A2QI\n",
       "488  TCGA.D8.A1XC\n",
       "489  TCGA.E2.A1IJ\n",
       "490  TCGA.E2.A14U\n",
       "491  TCGA.EW.A6SC\n",
       "\n",
       "[492 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_82B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up autoencoder model\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, embed_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        output = self.decoder(latent)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#train_torch = torch.FloatTensor(train_scaled)\n",
    "#test_torch = torch.FloatTensor(test_scaled)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "k = 10\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=123, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train function and validation function\n",
    "def train_epoch(model, device, optimizer, loss_func, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for features in dataloader:\n",
    "        features = features.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = loss_func(output, features)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "\n",
    "    return train_loss\n",
    "  \n",
    "def validation_epoch(model, device, loss_func, dataloader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    for features in dataloader:\n",
    "        features = features.to(device)\n",
    "        output = model(features)\n",
    "        loss = loss_func(output, features)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    valid_loss = valid_loss/len(dataloader)\n",
    "\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast 7:3 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 335855)\n",
      "(431, 335855)\n",
      "(185, 335855)\n"
     ]
    }
   ],
   "source": [
    "train_breast_73B = methy_breast_update.merge(train_idx_73B, on='attrib_name', how=\"inner\")\n",
    "test_breast_73B = methy_breast_update.merge(test_idx_73B, on='attrib_name', how=\"inner\")\n",
    "\n",
    "\n",
    "print(methy_breast_update.shape)\n",
    "print(train_breast_73B.shape)\n",
    "print(test_breast_73B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrib_name               0\n",
      "RBL2_cg00000029           0\n",
      "VDAC3_cg00000236          0\n",
      "ACTN1_cg00000289          0\n",
      "ATP2A1_cg00000292         0\n",
      "                         ..\n",
      "SNORD66_ch.3.3596501R    19\n",
      "FAM13B_ch.5.2533205R     20\n",
      "PKD2L2_ch.5.2533205R     20\n",
      "HNRNPK_ch.9.1116984R     31\n",
      "MIR7-1_ch.9.1116984R     31\n",
      "Length: 335855, dtype: int64\n",
      "attrib_name              0\n",
      "RBL2_cg00000029          0\n",
      "VDAC3_cg00000236         0\n",
      "ACTN1_cg00000289         0\n",
      "ATP2A1_cg00000292        0\n",
      "                        ..\n",
      "SNORD66_ch.3.3596501R    0\n",
      "FAM13B_ch.5.2533205R     0\n",
      "PKD2L2_ch.5.2533205R     0\n",
      "HNRNPK_ch.9.1116984R     0\n",
      "MIR7-1_ch.9.1116984R     0\n",
      "Length: 335855, dtype: int64\n",
      "---------------------------------\n",
      "attrib_name              0\n",
      "RBL2_cg00000029          0\n",
      "VDAC3_cg00000236         0\n",
      "ACTN1_cg00000289         0\n",
      "ATP2A1_cg00000292        0\n",
      "                        ..\n",
      "SNORD66_ch.3.3596501R    3\n",
      "FAM13B_ch.5.2533205R     5\n",
      "PKD2L2_ch.5.2533205R     5\n",
      "HNRNPK_ch.9.1116984R     8\n",
      "MIR7-1_ch.9.1116984R     8\n",
      "Length: 335855, dtype: int64\n",
      "attrib_name              0\n",
      "RBL2_cg00000029          0\n",
      "VDAC3_cg00000236         0\n",
      "ACTN1_cg00000289         0\n",
      "ATP2A1_cg00000292        0\n",
      "                        ..\n",
      "SNORD66_ch.3.3596501R    0\n",
      "FAM13B_ch.5.2533205R     0\n",
      "PKD2L2_ch.5.2533205R     0\n",
      "HNRNPK_ch.9.1116984R     0\n",
      "MIR7-1_ch.9.1116984R     0\n",
      "Length: 335855, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fill empty value with mean of each column\n",
    "\n",
    "print(train_breast_73B.isna().sum())\n",
    "train_breast_73B = train_breast_73B.fillna(train_breast_73B.mean())\n",
    "print(train_breast_73B.isna().sum())\n",
    "print(\"---------------------------------\")\n",
    "print(test_breast_73B.isna().sum())\n",
    "test_breast_73B= test_breast_73B.fillna(test_breast_73B.mean())\n",
    "print(test_breast_73B.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 335854)\n",
      "(185, 335854)\n"
     ]
    }
   ],
   "source": [
    "train_breast_73 = train_breast_73B.iloc[:, 1:]\n",
    "test_breast_73 = test_breast_73B.iloc[:, 1:]\n",
    "print(train_breast_73.shape)\n",
    "print(test_breast_73.shape)\n",
    "train_breast73_numpy = train_breast_73.to_numpy()\n",
    "test_breast73_numpy = test_breast_73.to_numpy()\n",
    "\n",
    "scaler_breast73 = MinMaxScaler()\n",
    "train_breast73_scaled = scaler_breast73.fit_transform(train_breast73_numpy)\n",
    "test_breast73_scaled = scaler_breast73.transform(test_breast73_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor type\n",
    "train_breast73_torch = torch.FloatTensor(train_breast73_scaled)\n",
    "test_breast73_torch = torch.FloatTensor(test_breast73_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the attrib_name\n",
    "train_breast73_name = train_breast_73B.iloc[:, 0]\n",
    "test_breast73_name = test_breast_73B.iloc[:, 0]\n",
    "print(train_breast73_name)\n",
    "print(test_breast73_name)\n",
    "\n",
    "train_breast73_name.to_csv(\"train_73B_idx.csv\")\n",
    "test_breast73_name.to_csv(\"test_73B_idx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast 7:3 training and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "epoch [1/10], train_loss:0.5057, valid_loss:0.2119\n",
      "epoch [2/10], train_loss:0.1353, valid_loss:0.0563\n",
      "epoch [3/10], train_loss:0.0543, valid_loss:0.0333\n",
      "epoch [4/10], train_loss:0.0422, valid_loss:0.0346\n",
      "epoch [5/10], train_loss:0.0338, valid_loss:0.0270\n",
      "epoch [6/10], train_loss:0.0291, valid_loss:0.0249\n",
      "epoch [7/10], train_loss:0.0294, valid_loss:0.0236\n",
      "epoch [8/10], train_loss:0.0265, valid_loss:0.0226\n",
      "epoch [9/10], train_loss:0.0277, valid_loss:0.0225\n",
      "epoch [10/10], train_loss:0.0239, valid_loss:0.0224\n",
      "Fold:  2\n",
      "epoch [1/10], train_loss:0.5014, valid_loss:0.2166\n",
      "epoch [2/10], train_loss:0.1358, valid_loss:0.0586\n",
      "epoch [3/10], train_loss:0.0457, valid_loss:0.0411\n",
      "epoch [4/10], train_loss:0.0366, valid_loss:0.0343\n",
      "epoch [5/10], train_loss:0.0313, valid_loss:0.0314\n",
      "epoch [6/10], train_loss:0.0278, valid_loss:0.0302\n",
      "epoch [7/10], train_loss:0.0262, valid_loss:0.0295\n",
      "epoch [8/10], train_loss:0.0265, valid_loss:0.0283\n",
      "epoch [9/10], train_loss:0.0245, valid_loss:0.0280\n",
      "epoch [10/10], train_loss:0.0232, valid_loss:0.0283\n",
      "Fold:  3\n",
      "epoch [1/10], train_loss:0.5084, valid_loss:0.2230\n",
      "epoch [2/10], train_loss:0.1551, valid_loss:0.0673\n",
      "epoch [3/10], train_loss:0.0591, valid_loss:0.0390\n",
      "epoch [4/10], train_loss:0.0356, valid_loss:0.0311\n",
      "epoch [5/10], train_loss:0.0307, valid_loss:0.0278\n",
      "epoch [6/10], train_loss:0.0269, valid_loss:0.0257\n",
      "epoch [7/10], train_loss:0.0254, valid_loss:0.0250\n",
      "epoch [8/10], train_loss:0.0249, valid_loss:0.0245\n",
      "epoch [9/10], train_loss:0.0245, valid_loss:0.0244\n",
      "epoch [10/10], train_loss:0.0291, valid_loss:0.0247\n",
      "Fold:  4\n",
      "epoch [1/10], train_loss:0.5053, valid_loss:0.2331\n",
      "epoch [2/10], train_loss:0.1425, valid_loss:0.0699\n",
      "epoch [3/10], train_loss:0.0538, valid_loss:0.0371\n",
      "epoch [4/10], train_loss:0.0328, valid_loss:0.0333\n",
      "epoch [5/10], train_loss:0.0308, valid_loss:0.0316\n",
      "epoch [6/10], train_loss:0.0286, valid_loss:0.0303\n",
      "epoch [7/10], train_loss:0.0290, valid_loss:0.0300\n",
      "epoch [8/10], train_loss:0.0252, valid_loss:0.0277\n",
      "epoch [9/10], train_loss:0.0261, valid_loss:0.0277\n",
      "epoch [10/10], train_loss:0.0245, valid_loss:0.0278\n",
      "Fold:  5\n",
      "epoch [1/10], train_loss:0.5056, valid_loss:0.1791\n",
      "epoch [2/10], train_loss:0.1208, valid_loss:0.0626\n",
      "epoch [3/10], train_loss:0.0520, valid_loss:0.0403\n",
      "epoch [4/10], train_loss:0.0419, valid_loss:0.0312\n",
      "epoch [5/10], train_loss:0.0319, valid_loss:0.0288\n",
      "epoch [6/10], train_loss:0.0270, valid_loss:0.0268\n",
      "epoch [7/10], train_loss:0.0256, valid_loss:0.0262\n",
      "epoch [8/10], train_loss:0.0241, valid_loss:0.0254\n",
      "epoch [9/10], train_loss:0.0283, valid_loss:0.0256\n",
      "epoch [10/10], train_loss:0.0233, valid_loss:0.0249\n",
      "Fold:  6\n",
      "epoch [1/10], train_loss:0.5202, valid_loss:0.2216\n",
      "epoch [2/10], train_loss:0.1454, valid_loss:0.0684\n",
      "epoch [3/10], train_loss:0.0516, valid_loss:0.0377\n",
      "epoch [4/10], train_loss:0.0379, valid_loss:0.0322\n",
      "epoch [5/10], train_loss:0.0297, valid_loss:0.0297\n",
      "epoch [6/10], train_loss:0.0251, valid_loss:0.0294\n",
      "epoch [7/10], train_loss:0.0255, valid_loss:0.0274\n",
      "epoch [8/10], train_loss:0.0246, valid_loss:0.0270\n",
      "epoch [9/10], train_loss:0.0270, valid_loss:0.0270\n",
      "epoch [10/10], train_loss:0.0261, valid_loss:0.0266\n",
      "Fold:  7\n",
      "epoch [1/10], train_loss:0.5122, valid_loss:0.2152\n",
      "epoch [2/10], train_loss:0.1435, valid_loss:0.0609\n",
      "epoch [3/10], train_loss:0.0498, valid_loss:0.0385\n",
      "epoch [4/10], train_loss:0.0347, valid_loss:0.0310\n",
      "epoch [5/10], train_loss:0.0294, valid_loss:0.0279\n",
      "epoch [6/10], train_loss:0.0270, valid_loss:0.0271\n",
      "epoch [7/10], train_loss:0.0279, valid_loss:0.0258\n",
      "epoch [8/10], train_loss:0.0260, valid_loss:0.0249\n",
      "epoch [9/10], train_loss:0.0257, valid_loss:0.0250\n",
      "epoch [10/10], train_loss:0.0234, valid_loss:0.0245\n",
      "Fold:  8\n",
      "epoch [1/10], train_loss:0.5223, valid_loss:0.2339\n",
      "epoch [2/10], train_loss:0.1433, valid_loss:0.0662\n",
      "epoch [3/10], train_loss:0.0480, valid_loss:0.0342\n",
      "epoch [4/10], train_loss:0.0384, valid_loss:0.0317\n",
      "epoch [5/10], train_loss:0.0338, valid_loss:0.0292\n",
      "epoch [6/10], train_loss:0.0291, valid_loss:0.0277\n",
      "epoch [7/10], train_loss:0.0274, valid_loss:0.0255\n",
      "epoch [8/10], train_loss:0.0250, valid_loss:0.0238\n",
      "epoch [9/10], train_loss:0.0264, valid_loss:0.0239\n",
      "epoch [10/10], train_loss:0.0286, valid_loss:0.0255\n",
      "Fold:  9\n",
      "epoch [1/10], train_loss:0.4949, valid_loss:0.1939\n",
      "epoch [2/10], train_loss:0.1254, valid_loss:0.0666\n",
      "epoch [3/10], train_loss:0.0605, valid_loss:0.0594\n",
      "epoch [4/10], train_loss:0.0414, valid_loss:0.0370\n",
      "epoch [5/10], train_loss:0.0307, valid_loss:0.0323\n",
      "epoch [6/10], train_loss:0.0275, valid_loss:0.0310\n",
      "epoch [7/10], train_loss:0.0274, valid_loss:0.0299\n",
      "epoch [8/10], train_loss:0.0252, valid_loss:0.0290\n",
      "epoch [9/10], train_loss:0.0229, valid_loss:0.0288\n",
      "epoch [10/10], train_loss:0.0247, valid_loss:0.0285\n",
      "Fold:  10\n",
      "epoch [1/10], train_loss:0.5035, valid_loss:0.2109\n",
      "epoch [2/10], train_loss:0.1393, valid_loss:0.0557\n",
      "epoch [3/10], train_loss:0.0470, valid_loss:0.0334\n",
      "epoch [4/10], train_loss:0.0325, valid_loss:0.0290\n",
      "epoch [5/10], train_loss:0.0299, valid_loss:0.0264\n",
      "epoch [6/10], train_loss:0.0307, valid_loss:0.0244\n",
      "epoch [7/10], train_loss:0.0297, valid_loss:0.0261\n",
      "epoch [8/10], train_loss:0.0250, valid_loss:0.0245\n",
      "epoch [9/10], train_loss:0.0269, valid_loss:0.0237\n",
      "epoch [10/10], train_loss:0.0237, valid_loss:0.0233\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "train_fold_loss = []\n",
    "valid_fold_loss = []\n",
    "embed_dim = train_breast73_torch.shape[1]\n",
    "\n",
    "# assign train_torch and test_torch\n",
    "train_torch = train_breast73_torch\n",
    "test_torch = test_breast73_torch\n",
    "\n",
    "for k, (train_idx,valid_idx) in enumerate(kfold.split(np.arange(len(train_torch)))):\n",
    "    \n",
    "    print('Fold: ', k+1 )\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      train_torch, batch_size=batch_size, sampler=train_sampler\n",
    "  )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "      train_torch, batch_size=batch_size, sampler=valid_sampler\n",
    "  )\n",
    "\n",
    "    model = autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, device, optimizer, criterion, train_loader)\n",
    "        valid_loss = validation_epoch(model, device, criterion, valid_loader)\n",
    "\n",
    "        print('epoch [{}/{}], train_loss:{:.4f}, valid_loss:{:.4f}'\n",
    "          .format(epoch + 1, epochs, train_loss, valid_loss))\n",
    "    \n",
    "    train_fold_loss.append(train_loss)\n",
    "    valid_fold_loss.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw diagram for 10 fold loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], train_loss:0.5043\n",
      "epoch [2/10], train_loss:0.1348\n",
      "epoch [3/10], train_loss:0.0497\n",
      "epoch [4/10], train_loss:0.0372\n",
      "epoch [5/10], train_loss:0.0312\n",
      "epoch [6/10], train_loss:0.0283\n",
      "epoch [7/10], train_loss:0.0269\n",
      "epoch [8/10], train_loss:0.0258\n",
      "epoch [9/10], train_loss:0.0252\n",
      "epoch [10/10], train_loss:0.0246\n"
     ]
    }
   ],
   "source": [
    "# formal training\n",
    "embed_dim = train_breast73_torch.shape[1]\n",
    "\n",
    "\n",
    "train_breast73_loader = torch.utils.data.DataLoader(\n",
    "      train_breast73_torch, batch_size=batch_size, shuffle=True\n",
    "  )\n",
    "test_breast73_loader = torch.utils.data.DataLoader(\n",
    "      test_breast73_torch, batch_size=batch_size, shuffle=False\n",
    "  )\n",
    "\n",
    "model_methy_73B = autoencoder().to(device)\n",
    "optimizer = optim.Adam(model_methy_73B.parameters(), lr=lr)\n",
    "                    \n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model_methy_73B, device, optimizer, criterion, train_breast73_loader)\n",
    "\n",
    "    print('epoch [{}/{}], train_loss:{:.4f}'\n",
    "        .format(epoch + 1, epochs, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x237c4069a00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Breast Methylation training\", loc=\"left\")\n",
    "plt.title(\"optimal latent size: 256\", loc=\"right\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "loss = [0.5043, 0.1348, 0.0497, 0.0372, 0.0312, 0.0283, 0.0269, 0.0258, 0.0252, 0.0246]\n",
    "plt.plot(range(1,11), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type autoencoder. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=335854, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=1024, out_features=335854, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load the model\n",
    "torch.save(model_methy_73B, \"methy_73B.pt\")\n",
    "\n",
    "methy_73B = torch.load(\"methy_73B.pt\")\n",
    "methy_73B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([431, 256])\n",
      "tensor([[-3.8543,  2.9750,  1.4633,  ...,  1.6653,  1.6093,  1.2630],\n",
      "        [-4.0798,  3.1637,  1.5636,  ...,  1.6746,  1.8015,  1.5152],\n",
      "        [-4.3704,  3.3216,  1.7542,  ...,  1.7844,  1.9014,  1.6852],\n",
      "        ...,\n",
      "        [-3.5853,  2.8613,  1.2501,  ...,  1.5577,  1.5758,  1.2946],\n",
      "        [-4.3588,  3.3441,  1.6394,  ...,  1.8042,  1.8744,  1.6326],\n",
      "        [-3.3975,  2.8514,  1.1673,  ...,  1.6179,  1.4575,  1.2255]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# for train data only\n",
    "methy_Tr73B_output = methy_73B.encoder(train_breast73_torch)\n",
    "print(methy_Tr73B_output.shape)\n",
    "print(methy_Tr73B_output)\n",
    "methy_Tr73B_output = methy_Tr73B_output.cpu().detach().numpy()\n",
    "np.savetxt('methy_Tr73B.csv', methy_Tr73B_output, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=335854, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=1024, out_features=335854, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test data only\n",
    "methy73B = torch.load('methy_73B.pt')\n",
    "methy73B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([185, 256])\n",
      "tensor([[-3.9318,  3.0726,  1.4551,  ...,  1.6895,  1.6813,  1.4507],\n",
      "        [-3.8185,  3.0313,  1.3256,  ...,  1.7260,  1.6063,  1.5084],\n",
      "        [-3.7031,  2.9749,  1.2746,  ...,  1.6596,  1.5919,  1.4191],\n",
      "        ...,\n",
      "        [-4.7298,  3.6131,  1.9112,  ...,  1.9490,  2.0221,  1.8171],\n",
      "        [-4.1550,  3.2284,  1.4967,  ...,  1.8667,  1.7181,  1.5702],\n",
      "        [-4.4544,  3.3996,  1.7519,  ...,  1.8849,  1.8532,  1.6689]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "methy_Test73B_output = methy73B.encoder(test_breast73_torch)\n",
    "print(methy_Test73B_output.shape)\n",
    "print(methy_Test73B_output)\n",
    "methy_Test73B_output = methy_Test73B_output.cpu().detach().numpy()\n",
    "np.savetxt('methy_Test73B.csv', methy_Test73B_output, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for whole data only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast 8:2 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 335855)\n",
      "(492, 335855)\n",
      "(124, 335855)\n"
     ]
    }
   ],
   "source": [
    "train_breast_82B = methy_breast_update.merge(train_idx_82B, on='attrib_name', how=\"inner\")\n",
    "test_breast_82B = methy_breast_update.merge(test_idx_82B, on='attrib_name', how=\"inner\")\n",
    "\n",
    "\n",
    "print(methy_breast_update.shape)\n",
    "print(train_breast_82B.shape)\n",
    "print(test_breast_82B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_breast_82B.isna().sum())\n",
    "train_breast_82B = train_breast_82B.fillna(train_breast_82B.mean())\n",
    "print(train_breast_82B.isna().sum())\n",
    "print(\"---------------------------------\")\n",
    "print(test_breast_82B.isna().sum())\n",
    "test_breast_82B= test_breast_82B.fillna(test_breast_82B.mean())\n",
    "print(test_breast_82B.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 335854)\n",
      "(124, 335854)\n"
     ]
    }
   ],
   "source": [
    "train_breast_82 = train_breast_82B.iloc[:, 1:]\n",
    "test_breast_82 = test_breast_82B.iloc[:, 1:]\n",
    "print(train_breast_82.shape)\n",
    "print(test_breast_82.shape)\n",
    "train_breast82_numpy = train_breast_82.to_numpy()\n",
    "test_breast82_numpy = test_breast_82.to_numpy()\n",
    "\n",
    "scaler_breast82 = MinMaxScaler()\n",
    "train_breast82_scaled = scaler_breast82.fit_transform(train_breast82_numpy)\n",
    "test_breast82_scaled = scaler_breast82.transform(test_breast82_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor type\n",
    "train_breast82_torch = torch.FloatTensor(train_breast82_scaled)\n",
    "test_breast82_torch = torch.FloatTensor(test_breast82_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      TCGA.3C.AAAU\n",
      "1      TCGA.3C.AALI\n",
      "2      TCGA.3C.AALJ\n",
      "3      TCGA.3C.AALK\n",
      "4      TCGA.4H.AAAK\n",
      "           ...     \n",
      "487    TCGA.WT.AB41\n",
      "488    TCGA.XX.A899\n",
      "489    TCGA.XX.A89A\n",
      "490    TCGA.Z7.A8R5\n",
      "491    TCGA.Z7.A8R6\n",
      "Name: attrib_name, Length: 492, dtype: object\n",
      "0      TCGA.5L.AAT0\n",
      "1      TCGA.A1.A0SF\n",
      "2      TCGA.A1.A0SI\n",
      "3      TCGA.A1.A0SQ\n",
      "4      TCGA.A2.A25E\n",
      "           ...     \n",
      "119    TCGA.PL.A8LX\n",
      "120    TCGA.S3.AA12\n",
      "121    TCGA.S3.AA17\n",
      "122    TCGA.W8.A86G\n",
      "123    TCGA.WT.AB44\n",
      "Name: attrib_name, Length: 124, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#save the attrib_name\n",
    "train_breast82_name = train_breast_82B.iloc[:, 0]\n",
    "test_breast82_name = test_breast_82B.iloc[:, 0]\n",
    "print(train_breast82_name)\n",
    "print(test_breast82_name)\n",
    "\n",
    "train_breast82_name.to_csv(\"train_82B_idx.csv\")\n",
    "test_breast82_name.to_csv(\"test_82B_idx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast 8:2 training and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "epoch [1/10], train_loss:0.4999, valid_loss:0.1857\n",
      "epoch [2/10], train_loss:0.1230, valid_loss:0.0691\n",
      "epoch [3/10], train_loss:0.0502, valid_loss:0.0364\n",
      "epoch [4/10], train_loss:0.0337, valid_loss:0.0306\n",
      "epoch [5/10], train_loss:0.0293, valid_loss:0.0273\n",
      "epoch [6/10], train_loss:0.0268, valid_loss:0.0263\n",
      "epoch [7/10], train_loss:0.0259, valid_loss:0.0261\n",
      "epoch [8/10], train_loss:0.0257, valid_loss:0.0252\n",
      "epoch [9/10], train_loss:0.0249, valid_loss:0.0255\n",
      "epoch [10/10], train_loss:0.0248, valid_loss:0.0248\n",
      "Fold:  2\n",
      "epoch [1/10], train_loss:0.5201, valid_loss:0.2510\n",
      "epoch [2/10], train_loss:0.1490, valid_loss:0.0622\n",
      "epoch [3/10], train_loss:0.0518, valid_loss:0.0342\n",
      "epoch [4/10], train_loss:0.0339, valid_loss:0.0282\n",
      "epoch [5/10], train_loss:0.0297, valid_loss:0.0251\n",
      "epoch [6/10], train_loss:0.0276, valid_loss:0.0239\n",
      "epoch [7/10], train_loss:0.0263, valid_loss:0.0228\n",
      "epoch [8/10], train_loss:0.0253, valid_loss:0.0222\n",
      "epoch [9/10], train_loss:0.0251, valid_loss:0.0219\n",
      "epoch [10/10], train_loss:0.0248, valid_loss:0.0216\n",
      "Fold:  3\n",
      "epoch [1/10], train_loss:0.5465, valid_loss:0.2357\n",
      "epoch [2/10], train_loss:0.1533, valid_loss:0.0676\n",
      "epoch [3/10], train_loss:0.0505, valid_loss:0.0365\n",
      "epoch [4/10], train_loss:0.0331, valid_loss:0.0299\n",
      "epoch [5/10], train_loss:0.0292, valid_loss:0.0269\n",
      "epoch [6/10], train_loss:0.0267, valid_loss:0.0254\n",
      "epoch [7/10], train_loss:0.0254, valid_loss:0.0252\n",
      "epoch [8/10], train_loss:0.0254, valid_loss:0.0251\n",
      "epoch [9/10], train_loss:0.0248, valid_loss:0.0240\n",
      "epoch [10/10], train_loss:0.0243, valid_loss:0.0237\n",
      "Fold:  4\n",
      "epoch [1/10], train_loss:0.4988, valid_loss:0.1883\n",
      "epoch [2/10], train_loss:0.1273, valid_loss:0.0604\n",
      "epoch [3/10], train_loss:0.0512, valid_loss:0.0567\n",
      "epoch [4/10], train_loss:0.0409, valid_loss:0.0336\n",
      "epoch [5/10], train_loss:0.0308, valid_loss:0.0300\n",
      "epoch [6/10], train_loss:0.0274, valid_loss:0.0278\n",
      "epoch [7/10], train_loss:0.0256, valid_loss:0.0269\n",
      "epoch [8/10], train_loss:0.0251, valid_loss:0.0261\n",
      "epoch [9/10], train_loss:0.0248, valid_loss:0.0257\n",
      "epoch [10/10], train_loss:0.0239, valid_loss:0.0255\n",
      "Fold:  5\n",
      "epoch [1/10], train_loss:0.5095, valid_loss:0.2172\n",
      "epoch [2/10], train_loss:0.1391, valid_loss:0.0556\n",
      "epoch [3/10], train_loss:0.0501, valid_loss:0.0331\n",
      "epoch [4/10], train_loss:0.0353, valid_loss:0.0307\n",
      "epoch [5/10], train_loss:0.0304, valid_loss:0.0268\n",
      "epoch [6/10], train_loss:0.0275, valid_loss:0.0255\n",
      "epoch [7/10], train_loss:0.0260, valid_loss:0.0243\n",
      "epoch [8/10], train_loss:0.0252, valid_loss:0.0237\n",
      "epoch [9/10], train_loss:0.0247, valid_loss:0.0235\n",
      "epoch [10/10], train_loss:0.0244, valid_loss:0.0232\n",
      "Fold:  6\n",
      "epoch [1/10], train_loss:0.5112, valid_loss:0.1719\n",
      "epoch [2/10], train_loss:0.1214, valid_loss:0.0517\n",
      "epoch [3/10], train_loss:0.0429, valid_loss:0.0358\n",
      "epoch [4/10], train_loss:0.0323, valid_loss:0.0303\n",
      "epoch [5/10], train_loss:0.0283, valid_loss:0.0275\n",
      "epoch [6/10], train_loss:0.0264, valid_loss:0.0263\n",
      "epoch [7/10], train_loss:0.0252, valid_loss:0.0257\n",
      "epoch [8/10], train_loss:0.0248, valid_loss:0.0254\n",
      "epoch [9/10], train_loss:0.0245, valid_loss:0.0251\n",
      "epoch [10/10], train_loss:0.0240, valid_loss:0.0250\n",
      "Fold:  7\n",
      "epoch [1/10], train_loss:0.5127, valid_loss:0.2137\n",
      "epoch [2/10], train_loss:0.1474, valid_loss:0.0692\n",
      "epoch [3/10], train_loss:0.0506, valid_loss:0.0419\n",
      "epoch [4/10], train_loss:0.0375, valid_loss:0.0365\n",
      "epoch [5/10], train_loss:0.0318, valid_loss:0.0320\n",
      "epoch [6/10], train_loss:0.0279, valid_loss:0.0289\n",
      "epoch [7/10], train_loss:0.0259, valid_loss:0.0277\n",
      "epoch [8/10], train_loss:0.0245, valid_loss:0.0272\n",
      "epoch [9/10], train_loss:0.0246, valid_loss:0.0269\n",
      "epoch [10/10], train_loss:0.0240, valid_loss:0.0267\n",
      "Fold:  8\n",
      "epoch [1/10], train_loss:0.5120, valid_loss:0.2076\n",
      "epoch [2/10], train_loss:0.1240, valid_loss:0.0568\n",
      "epoch [3/10], train_loss:0.0444, valid_loss:0.0355\n",
      "epoch [4/10], train_loss:0.0323, valid_loss:0.0308\n",
      "epoch [5/10], train_loss:0.0285, valid_loss:0.0277\n",
      "epoch [6/10], train_loss:0.0264, valid_loss:0.0263\n",
      "epoch [7/10], train_loss:0.0256, valid_loss:0.0255\n",
      "epoch [8/10], train_loss:0.0250, valid_loss:0.0256\n",
      "epoch [9/10], train_loss:0.0244, valid_loss:0.0249\n",
      "epoch [10/10], train_loss:0.0241, valid_loss:0.0249\n",
      "Fold:  9\n",
      "epoch [1/10], train_loss:0.4948, valid_loss:0.1972\n",
      "epoch [2/10], train_loss:0.1266, valid_loss:0.0540\n",
      "epoch [3/10], train_loss:0.0470, valid_loss:0.0348\n",
      "epoch [4/10], train_loss:0.0329, valid_loss:0.0293\n",
      "epoch [5/10], train_loss:0.0283, valid_loss:0.0267\n",
      "epoch [6/10], train_loss:0.0267, valid_loss:0.0254\n",
      "epoch [7/10], train_loss:0.0253, valid_loss:0.0246\n",
      "epoch [8/10], train_loss:0.0251, valid_loss:0.0241\n",
      "epoch [9/10], train_loss:0.0246, valid_loss:0.0239\n",
      "epoch [10/10], train_loss:0.0236, valid_loss:0.0238\n",
      "Fold:  10\n",
      "epoch [1/10], train_loss:0.4977, valid_loss:0.1979\n",
      "epoch [2/10], train_loss:0.1301, valid_loss:0.0808\n",
      "epoch [3/10], train_loss:0.0541, valid_loss:0.0366\n",
      "epoch [4/10], train_loss:0.0334, valid_loss:0.0313\n",
      "epoch [5/10], train_loss:0.0292, valid_loss:0.0282\n",
      "epoch [6/10], train_loss:0.0284, valid_loss:0.0275\n",
      "epoch [7/10], train_loss:0.0262, valid_loss:0.0268\n",
      "epoch [8/10], train_loss:0.0258, valid_loss:0.0256\n",
      "epoch [9/10], train_loss:0.0248, valid_loss:0.0249\n",
      "epoch [10/10], train_loss:0.0245, valid_loss:0.0246\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "train_fold_loss = []\n",
    "valid_fold_loss = []\n",
    "embed_dim = train_breast82_torch.shape[1]\n",
    "\n",
    "# assign train_torch and test_torch\n",
    "train_torch = train_breast82_torch\n",
    "test_torch = test_breast82_torch\n",
    "\n",
    "for k, (train_idx,valid_idx) in enumerate(kfold.split(np.arange(len(train_torch)))):\n",
    "    \n",
    "    print('Fold: ', k+1 )\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      train_torch, batch_size=batch_size, sampler=train_sampler\n",
    "  )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "      train_torch, batch_size=batch_size, sampler=valid_sampler\n",
    "  )\n",
    "\n",
    "    model = autoencoder().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, device, optimizer, criterion, train_loader)\n",
    "        valid_loss = validation_epoch(model, device, criterion, valid_loader)\n",
    "\n",
    "        print('epoch [{}/{}], train_loss:{:.4f}, valid_loss:{:.4f}'\n",
    "          .format(epoch + 1, epochs, train_loss, valid_loss))\n",
    "    \n",
    "    train_fold_loss.append(train_loss)\n",
    "    valid_fold_loss.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], train_loss:0.5158\n",
      "epoch [2/10], train_loss:0.1368\n",
      "epoch [3/10], train_loss:0.0505\n",
      "epoch [4/10], train_loss:0.0350\n",
      "epoch [5/10], train_loss:0.0300\n",
      "epoch [6/10], train_loss:0.0273\n",
      "epoch [7/10], train_loss:0.0258\n",
      "epoch [8/10], train_loss:0.0250\n",
      "epoch [9/10], train_loss:0.0246\n",
      "epoch [10/10], train_loss:0.0244\n"
     ]
    }
   ],
   "source": [
    "# formal training\n",
    "train_breast82_loader = torch.utils.data.DataLoader(\n",
    "      train_breast82_torch, batch_size=batch_size, shuffle=True\n",
    "  )\n",
    "test_breast82_loader = torch.utils.data.DataLoader(\n",
    "      test_breast82_torch, batch_size=batch_size, shuffle=False\n",
    "  )\n",
    "\n",
    "model_methy_82B = autoencoder().to(device)\n",
    "optimizer = optim.Adam(model_methy_82B.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model_methy_82B, device, optimizer, criterion, train_breast82_loader)\n",
    "\n",
    "    print('epoch [{}/{}], train_loss:{:.4f}'\n",
    "        .format(epoch + 1, epochs, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type autoencoder. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=335854, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=1024, out_features=335854, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load the model\n",
    "torch.save(model_methy_82B, \"methy_82B.pt\")\n",
    "\n",
    "methy_82B = torch.load(\"methy_82B.pt\")\n",
    "methy_82B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([492, 256])\n",
      "tensor([[ 3.5710,  1.4257,  2.1970,  ..., -2.5272, -1.8212,  2.5967],\n",
      "        [ 3.7296,  1.5388,  2.3681,  ..., -2.7706, -1.9150,  2.7146],\n",
      "        [ 3.9683,  1.7149,  2.6789,  ..., -3.1441, -2.0104,  2.8725],\n",
      "        ...,\n",
      "        [ 3.2604,  1.2846,  1.9492,  ..., -2.2460, -1.7404,  2.4628],\n",
      "        [ 3.9428,  1.6234,  2.6157,  ..., -3.0173, -2.0498,  2.9230],\n",
      "        [ 3.1766,  1.2524,  1.7818,  ..., -2.1168, -1.6669,  2.4237]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# for train data only\n",
    "methy_Tr82B_output = methy_82B.encoder(train_breast82_torch)\n",
    "print(methy_Tr82B_output.shape)\n",
    "print(methy_Tr82B_output)\n",
    "methy_Tr82B_output = methy_Tr82B_output.cpu().detach().numpy()\n",
    "np.savetxt('methy_Tr82B.csv', methy_Tr82B_output, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=335854, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=1024, out_features=335854, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for test data only\n",
    "methy82B = torch.load('methy_82B.pt')\n",
    "methy82B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 256])\n",
      "tensor([[ 3.5870,  1.4484,  2.2740,  ..., -2.6455, -1.8562,  2.6672],\n",
      "        [ 3.4173,  1.4137,  2.0979,  ..., -2.4712, -1.8428,  2.6139],\n",
      "        [ 3.3464,  1.3543,  2.0041,  ..., -2.3498, -1.8122,  2.5525],\n",
      "        ...,\n",
      "        [ 3.8168,  1.6809,  2.5224,  ..., -3.0009, -2.0387,  2.8993],\n",
      "        [ 3.7411,  1.5333,  2.3327,  ..., -2.7540, -1.9547,  2.8322],\n",
      "        [ 4.0412,  1.7152,  2.6860,  ..., -3.1677, -2.0665,  2.9739]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "methy_Test82B_output = methy82B.encoder(test_breast82_torch)\n",
    "print(methy_Test82B_output.shape)\n",
    "print(methy_Test82B_output)\n",
    "methy_Test82B_output = methy_Test82B_output.cpu().detach().numpy()\n",
    "np.savetxt('methy_Test82B.csv', methy_Test82B_output, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
